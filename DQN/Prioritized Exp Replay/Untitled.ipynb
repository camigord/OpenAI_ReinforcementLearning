{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Prioritized Experience Replay\n",
    "\n",
    "Implementing the rank-based approach. Code based on contribution from [Damcy](https://github.com/Damcy/prioritized-experience-replay)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "from utils import BinaryHeap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experience_Buffer():\n",
    "    def __init__(self,memory_size):\n",
    "        self.memory_size = memory_size\n",
    "        # These are the arrays where we will store the experiences\n",
    "        self.actions = np.empty(self.memory_size,dtype=np.uint8)\n",
    "        self.rewards = np.empty(self.memory_size,dtype=np.integer)\n",
    "        self.screens = np.empty((self.memory_size, screen_height, screen_width),dtype=np.float16)\n",
    "        self.terminals = np.empty(self.memory_size,dtype=np.bool)\n",
    "        \n",
    "        self.prestates = np.empty((batch_size,history_length,screen_height, screen_width),dtype=np.float16)\n",
    "        self.poststates = np.empty((batch_size,history_length,screen_height, screen_width),dtype=np.float16)\n",
    "        self.current = 0     # Pointer to the current saving location\n",
    "        self.count = 0       # Number of collected experiences\n",
    "        \n",
    "    def add(self, screen, reward, action, terminal):\n",
    "        # Adds an experience to replay memory and increases pointers\n",
    "        self.actions[self.current] = action\n",
    "        self.rewards[self.current] = reward\n",
    "        self.screens[self.current,...] = screen\n",
    "        self.terminals[self.current] = terminal\n",
    "        \n",
    "        self.count = max(self.count, self.current+1)\n",
    "        self.current = (self.current + 1) % self.memory_size    # Pointer resets when reaching memory_size\n",
    "        \n",
    "    def getState(self,index):\n",
    "        index = index % self.count\n",
    "        # If index is not in the beginning, just use simple slicing\n",
    "        if index >= history_length-1:\n",
    "            return self.screens[(index-(history_length-1)):(index+1),...]\n",
    "        # Otherwise determine the list of indexes which need to be returned\n",
    "        else:\n",
    "            indexes = [(index-i) % self.count for i in reversed(range(history_length))]\n",
    "            return self.screens[indexes,...]\n",
    "        \n",
    "    def sample_from_replay(self):\n",
    "        # Sample random indexes\n",
    "        indexes = []\n",
    "        while len(indexes) < batch_size:\n",
    "            while True:\n",
    "                index = random.randint(history_length,self.count-1)\n",
    "                # If index wraps over current pointer, get new one\n",
    "                if index >= self.current and index - history_length < self.current:\n",
    "                    continue\n",
    "                # If index wraps over terminal state, get new one\n",
    "                if self.terminals[(index-history_length):index].any():\n",
    "                    continue\n",
    "                # Use the index otherwise\n",
    "                break\n",
    "            self.prestates[len(indexes),...] = self.getState(index-1)\n",
    "            self.poststates[len(indexes),...] = self.getState(index)\n",
    "            indexes.append(index)\n",
    "            \n",
    "        actions = self.actions[indexes]\n",
    "        rewards = self.rewards[indexes]\n",
    "        terminals = self.terminals[indexes]\n",
    "        \n",
    "        return np.transpose(self.prestates,(0,2,3,1)),actions,rewards,np.transpose(self.poststates,(0,2,3,1)),terminals    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Experience():\n",
    "    def __init__(self,memory_size):\n",
    "        self.size = memory_size\n",
    "        self.alpha = 0.7\n",
    "        self.beta_zero = 0.5\n",
    "        self.batch_size = 32        \n",
    "        self.partition_num = 100    # Split total size to N segments\n",
    "        \n",
    "        self.index = 0\n",
    "        self.record_size = 0\n",
    "        self.learn_start = 1000     # CHANGE\n",
    "        self._experience = {}\n",
    "        self.priority_queue = BinaryHeap(self.size)\n",
    "        self.distributions = self.build_distributions()\n",
    "        \n",
    "        self.beta_grad = (1-self.beta_zero) / (TOTAL_STEPS - LEARN_START)\n",
    "        \n",
    "    def build_distributions(self):\n",
    "        '''\n",
    "        Preprocess probabilities: (rank_i)^(-alpha) / sum((rank_i)^(-alpha))\n",
    "        '''\n",
    "        results = {}  \n",
    "        \n",
    "        # Creating different distributions according to the number of experiences which have been collected\n",
    "        partition_size = math.floor(self.size / self.partition_num)\n",
    "        current_partition = 1\n",
    "        \n",
    "        for n in range(partition_size,self.size+1,partition_size):\n",
    "            if self.learn_start <= n <= self.size:\n",
    "                distribution = {}\n",
    "                # P(i) = (rank_i)^(-alpha) / sum((rank_i)^(-alpha))\n",
    "                pdf = list(map(lambda x: math.pow(x,-self.alpha),range(1,n+1)))\n",
    "                pdf_sum = math.fsum(pdf)\n",
    "                distribution['pdf'] = list(map(lambda x: x/pdf_sum, pdf))\n",
    "                \n",
    "                # Split each distribution to K segments, setting k = batch_size\n",
    "                # strata_ends keeps start and end position of each segment\n",
    "                cdf = np.cumsum(distribution['pdf'])\n",
    "                strata_ends = {1: 0, self.batch_size+1: n}\n",
    "                step = 1/float(self.batch_size)\n",
    "                index = 1\n",
    "                for s in range(2,self.batch_size+1):\n",
    "                    while cdf[index] < step:\n",
    "                        index += 1\n",
    "                    strata_ends[s] = index\n",
    "                    step += 1/float(self.batch_size)\n",
    "                    \n",
    "                distribution['strata_ends'] = strata_ends\n",
    "                results[current_partition] = distribution\n",
    "            \n",
    "            current_partition += 1\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def store(self,experience):\n",
    "        '''\n",
    "        Store experience: experience is a tuple of (s1,a,r,s2,t)\n",
    "        '''\n",
    "        if self.record_size < self.size:\n",
    "            self.record_size += 1\n",
    "        if self.index % self.size == 0:\n",
    "            self.index = 1\n",
    "        else:\n",
    "            self.index += 1\n",
    "            \n",
    "        if self.index in self._experience:\n",
    "            del self._experience[self.index]\n",
    "        self._experience[self.index] = experience\n",
    "        # Add to priority queue\n",
    "        priority = self.priority_queue.get_max_priority()\n",
    "        self.priority_queue.update(priority,self.index)\n",
    "        \n",
    "    def retrieve(self,indices):\n",
    "        '''\n",
    "        Get experiences from indices\n",
    "        '''\n",
    "        return [self._experience[v] for v in indices]\n",
    "    \n",
    "    def rebalance(self):\n",
    "        '''\n",
    "        Rebalance priority queue\n",
    "        '''\n",
    "        self.priority_queue.balance_tree()\n",
    "        \n",
    "    def update_priority(self,indices,delta):\n",
    "        '''\n",
    "        Update the priority values according to new observations\n",
    "        '''\n",
    "        for i in range(0,len(indices)):\n",
    "            self.priority_queue.update(math.fabs(delta[i]),indices[i])\n",
    "    \n",
    "    def sample_from_replay(self,global_step):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3104488028397141, 0.1663653941798837, 0.11549970106682916, 0.0891530072831946, 0.07293180893490515, 0.061894757267151136, 0.05387679509211429, 0.04777591365571642, 0.042970630984892164, 0.03908318869559933]\n",
      "[ 0.3104488   0.4768142   0.5923139   0.68146691  0.75439871  0.81629347\n",
      "  0.87017027  0.91794618  0.96091681  1.        ]\n",
      "step: 0.20\n",
      "{1: 0, 2: 1, 3: 1, 4: 3, 5: 5, 6: 10}\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.9\n",
    "n = 10\n",
    "batch_size = 5\n",
    "\n",
    "distribution = {}\n",
    "# P(i) = (rank_i)^(-alpha) / sum((rank_i)^(-alpha))\n",
    "pdf = list(map(lambda x: math.pow(x,-alpha),range(1,n+1)))\n",
    "pdf_sum = math.fsum(pdf)\n",
    "distribution['pdf'] = list(map(lambda x: x/pdf_sum, pdf))\n",
    "\n",
    "print(distribution['pdf'])\n",
    "\n",
    "cdf = np.cumsum(distribution['pdf'])\n",
    "\n",
    "print(cdf)\n",
    "\n",
    "strata_ends = {1: 0, batch_size+1: n}\n",
    "step = 1/float(batch_size)\n",
    "print('step: %.2f' % step)\n",
    "index = 1\n",
    "for s in range(2,batch_size+1):\n",
    "    while cdf[index] < step:\n",
    "        index += 1\n",
    "    strata_ends[s] = index\n",
    "    step += 1/float(batch_size)\n",
    "\n",
    "distribution['strata_ends'] = strata_ends\n",
    "\n",
    "print(strata_ends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
